import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from google.colab import drive

# Mount Google Drive (You may have already done this)
drive.mount('/content/drive')

# Load the file from Google Drive
file_path = '/content/drive/My Drive/Colab Notebooks/train.csv'
selected_columns = ['ph_no', 'cvv', 'credit_card_number', '6aHwr', 'CbKM4', 'PwJxl', 'rWVvg', '98Zw0', '9buXh', 'state']

# Read only the selected columns from the CSV file
df = pd.read_csv(file_path, usecols=selected_columns)

# Handle missing values by imputing with the mean
df.fillna(df.mean(), inplace=True)

# Split data into training and testing sets
X = df.drop(columns=['state'])  # Features
y = df['state']  # Target variable

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize features (important for Logistic Regression)
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Train a Logistic Regression model
model = LogisticRegression()
model.fit(X_train, y_train)

# Evaluate the model
accuracy = model.score(X_test, y_test)
print(f'Accuracy: {accuracy}')
