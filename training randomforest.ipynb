import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from google.colab import drive

# Mount Google Drive (You may have already done this)
drive.mount('/content/drive')

# Load the file from Google Drive
file_path = '/content/drive/My Drive/Colab Notebooks/train.csv'
selected_columns = ['ph_no', 'cvv', 'credit_card_number', '6aHwr', 'CbKM4', 'PwJxl', 'rWVvg', '98Zw0', '9buXh', 'state']

# Read only the selected columns from the CSV file
df = pd.read_csv(file_path, usecols=selected_columns)

# Handle missing values by imputing with the mean
df.fillna(df.mean(), inplace=True)

# Split data into training and testing sets
X = df.drop(columns=['state'])  # Features
y = df['state']  # Target variable

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train a classification model (e.g., RandomForestClassifier)
model = RandomForestClassifier()
model.fit(X_train, y_train)

# Evaluate the model
accuracy = model.score(X_test, y_test)
print(f'Accuracy: {accuracy}')
