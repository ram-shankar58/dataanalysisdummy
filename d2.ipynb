import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from google.colab import drive

# Mount Google Drive (You may have already done this)
drive.mount('/content/drive')

# Load the file from Google Drive
file_path = '/content/drive/My Drive/Colab Notebooks/train.csv'
df = pd.read_csv(file_path)

# Handle missing values by imputing with the mean
df.fillna(df.mean(), inplace=True)

# Encode categorical variables using one-hot encoding for "job" and "country" columns
df = pd.get_dummies(df, columns=['job', 'country'], prefix=['job', 'country'])

# Create a copy of the DataFrame with non-numeric columns for reference
df_reference = df[['email', 'name', 'state']].copy()

# Drop non-numeric columns that can't be used in RandomForestClassifier
df.drop(columns=['email', 'name', 'state'], inplace=True)

# Scale numerical features
scaler = StandardScaler()
numerical_columns = ['ph_no', 'cvv', 'credit_card_number', '6aHwr', 'CbKM4', 'PwJxl', 'rWVvg', '98Zw0', '9buXh']
df[numerical_columns] = scaler.fit_transform(df[numerical_columns])

# Split data into training and testing sets
X = df  # Features (without non-numeric columns)
y = df_reference['state']  # Target variable
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train a classification model (e.g., RandomForestClassifier)
model = RandomForestClassifier()
model.fit(X_train, y_train)

# Evaluate the model
accuracy = model.score(X_test, y_test)
print(f'Accuracy: {accuracy}')
